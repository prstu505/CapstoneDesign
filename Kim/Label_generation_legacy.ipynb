{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: kiwipiepy in /home/work/.local/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: kiwipiepy-model<0.18,>=0.17 in /home/work/.local/lib/python3.10/site-packages (from kiwipiepy) (0.17.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (1.22.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kiwipiepy) (4.66.1)\n",
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
      "\u001b[33mDEPRECATION: devscripts 2.22.1ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kiwipiepy\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from transformers import BertTokenizerFast ,BertForMaskedLM,FillMaskPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiwi Tokens with POS: ['1989_SN', '년_NNB', '2_SN', '월_NNB', '15_SN', '일_NNB', '여의도_NNP', '농민_NNG', '폭력_NNG', '시위_NNG', '를_JKO', '주도_NNG', '하_XSV', 'ᆫ_ETM', '혐의_NNG', '로_JKB', '지명_NNG', '수배_NNG', '되_XSV', '었_EP', '다_EF', '._SF']\n",
      "Kiwi Tokens: ['1989', '년', '2', '월', '15', '일', '여의도', '농민', '폭력', '시위', '를', '주도', '하', 'ᆫ', '혐의', '로', '지명', '수배', '되', '었', '다', '.']\n",
      "KoBERT Tokens: ['1989', '년', '2', '월', '15', '일', '여의도', '농민', '폭력', '시위', '를', '주도', '하', '[UNK]', '혐의', '로', '지명', '수배', '되', '었', '다', '.']\n",
      "KoBERT Input IDs: [9190, 761, 22, 1479, 3749, 1507, 7915, 6290, 5206, 5754, 1022, 4682, 1889, 1, 4456, 991, 7119, 18627, 859, 1417, 809, 18]\n",
      "token Num: 22\n",
      "only_kobert_tokens: ['1989', '##년', '2', '##월', '15', '##일', '여의도', '농민', '폭력', '시위', '##를', '주도', '##한', '혐의', '##로', '지명', '##수', '##배', '##되', '##었', '##다', '.']\n",
      "KoBERT Tokens_pos: ['1989', '_', 'SN', '년', '_', 'N', '##N', '##B', '2', '_', 'SN', '월', '_', 'N', '##N', '##B', '15', '_', 'SN', '일', '_', 'N', '##N', '##B', '여의도', '_', 'N', '##N', '##P', '농민', '_', 'N', '##NG', '폭력', '_', 'N', '##NG', '시위', '_', 'N', '##NG', '를', '_', 'J', '##K', '##O', '주도', '_', 'N', '##NG', '하', '_', 'X', '##S', '##V', '[UNK]', '_', 'ET', '##M', '혐의', '_', 'N', '##NG', '로', '_', 'J', '##K', '##B', '지명', '_', 'N', '##NG', '수배', '_', 'N', '##NG', '되', '_', 'X', '##S', '##V', '었', '_', 'EP', '다', '_', 'E', '##F', '.', '_', 'SF']\n",
      "KoBERT Input IDs_pos: [9190, 66, 25817, 761, 66, 50, 2111, 2206, 22, 66, 25817, 1479, 66, 50, 2111, 2206, 3749, 66, 25817, 1507, 66, 50, 2111, 2206, 7915, 66, 50, 2111, 2325, 6290, 66, 50, 9029, 5206, 66, 50, 9029, 5754, 66, 50, 9029, 1022, 66, 46, 2213, 2185, 4682, 66, 50, 9029, 1889, 66, 60, 2238, 2392, 1, 66, 10413, 2110, 4456, 66, 50, 9029, 991, 66, 46, 2213, 2206, 7119, 66, 50, 9029, 18627, 66, 50, 9029, 859, 66, 60, 2238, 2392, 1417, 66, 15760, 809, 66, 41, 2314, 18, 66, 16371]\n",
      "token Num: 91\n"
     ]
    }
   ],
   "source": [
    "kiwi = Kiwi()\n",
    "text = \"1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의로 지명수배되었다.\"\n",
    "\n",
    "# 형태소 분석 및 품사 태깅\n",
    "result = kiwi.tokenize(text)\n",
    "\n",
    "# KoBERT 토크나이저 로드\n",
    "tokenizer = BertTokenizerFast.from_pretrained('klue/bert-base')\n",
    "\n",
    "# Kiwi 형태소 분석 결과를 문자열로 변환\n",
    "kiwi_tokens = [token.form for token in result]\n",
    "kiwi_text = ' '.join(kiwi_tokens)\n",
    "\n",
    "kiwi_tokens_with_pos = [f\"{token.form}_{token.tag}\" for token in result]\n",
    "kiwi_text_with_pos = ' '.join(kiwi_tokens_with_pos)\n",
    "\n",
    "print(\"Kiwi Tokens with POS:\", kiwi_tokens_with_pos)\n",
    "# KoBERT 토크나이저로 토크나이징\n",
    "kobert_tokens = tokenizer.tokenize(kiwi_text)\n",
    "kobert_input_ids = tokenizer.convert_tokens_to_ids(kobert_tokens)\n",
    "only_kobert_tokens = tokenizer.tokenize(text)\n",
    "kobert_tokens_pos = tokenizer.tokenize(kiwi_text_with_pos)\n",
    "kobert_input_ids_pos = tokenizer.convert_tokens_to_ids(kobert_tokens_pos)\n",
    "# 결과 출력\n",
    "\n",
    "print(\"Kiwi Tokens:\", kiwi_tokens)\n",
    "print(\"KoBERT Tokens:\", kobert_tokens)\n",
    "print(\"KoBERT Input IDs:\", kobert_input_ids)\n",
    "print(\"token Num:\",len(kobert_input_ids))\n",
    "\n",
    "print(\"only_kobert_tokens:\",only_kobert_tokens)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"KoBERT Tokens_pos:\", kobert_tokens_pos)\n",
    "print(\"KoBERT Input IDs_pos:\", kobert_input_ids_pos)\n",
    "print(\"token Num:\",len(kobert_input_ids_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./6_modern_data.json\", 'rb') as f :\n",
    "    data = json.load(f)\n",
    "\n",
    "sentence_token = []\n",
    "\n",
    "\n",
    "for info in enumerate(data.values()): \n",
    "    form = info[1][\"sentence\"]\n",
    "    form = form.replace(info[1][\"aux_tokens\"][0][\"form\"], \"[MASK]\")\n",
    "    sentence_token.append(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279\n",
      "13279\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_token))\n",
    "print(len(data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained('klue/bert-base')\n",
    "model = BertForMaskedLM.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"klue/bert-base\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.34.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1582077294588089,\n",
       "  'token': 28262,\n",
       "  'token_str': '산더미',\n",
       "  'sequence': '담쟁이란 여름 한철 벽을 온통 둘러싸고 지붕과 연돌의 붉은 빛난 남기고 집 안을 통째로 초록의 세상으로 변해 줄 때가 아름다운 것이지, 잎을 다 떨어뜨리고 앙상하게 드러난 벽에 메마른 줄기를 산더미 같이 둘러칠 때쯤에는 벌써 다시 지릅떠볼 값조차 없는 것이다.'},\n",
       " {'score': 0.06853462755680084,\n",
       "  'token': 28000,\n",
       "  'token_str': '깨알',\n",
       "  'sequence': '담쟁이란 여름 한철 벽을 온통 둘러싸고 지붕과 연돌의 붉은 빛난 남기고 집 안을 통째로 초록의 세상으로 변해 줄 때가 아름다운 것이지, 잎을 다 떨어뜨리고 앙상하게 드러난 벽에 메마른 줄기를 깨알 같이 둘러칠 때쯤에는 벌써 다시 지릅떠볼 값조차 없는 것이다.'},\n",
       " {'score': 0.055071957409381866,\n",
       "  'token': 809,\n",
       "  'token_str': '다',\n",
       "  'sequence': '담쟁이란 여름 한철 벽을 온통 둘러싸고 지붕과 연돌의 붉은 빛난 남기고 집 안을 통째로 초록의 세상으로 변해 줄 때가 아름다운 것이지, 잎을 다 떨어뜨리고 앙상하게 드러난 벽에 메마른 줄기를 다 같이 둘러칠 때쯤에는 벌써 다시 지릅떠볼 값조차 없는 것이다.'},\n",
       " {'score': 0.05441555753350258,\n",
       "  'token': 24083,\n",
       "  'token_str': '거미줄',\n",
       "  'sequence': '담쟁이란 여름 한철 벽을 온통 둘러싸고 지붕과 연돌의 붉은 빛난 남기고 집 안을 통째로 초록의 세상으로 변해 줄 때가 아름다운 것이지, 잎을 다 떨어뜨리고 앙상하게 드러난 벽에 메마른 줄기를 거미줄 같이 둘러칠 때쯤에는 벌써 다시 지릅떠볼 값조차 없는 것이다.'},\n",
       " {'score': 0.037816449999809265,\n",
       "  'token': 3657,\n",
       "  'token_str': '하나',\n",
       "  'sequence': '담쟁이란 여름 한철 벽을 온통 둘러싸고 지붕과 연돌의 붉은 빛난 남기고 집 안을 통째로 초록의 세상으로 변해 줄 때가 아름다운 것이지, 잎을 다 떨어뜨리고 앙상하게 드러난 벽에 메마른 줄기를 하나 같이 둘러칠 때쯤에는 벌써 다시 지릅떠볼 값조차 없는 것이다.'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip(sentence_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13279/13279 [11:57<00:00, 18.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 가정: `model`과 `tokenizer`는 이미 정의되어 있음\n",
    "pip = FillMaskPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "Similar_data = {\"data\": []}\n",
    "dict = {\"data\": [{\"para\": [{\"label\": [{}], \"context\": \"\"}]}]}\n",
    "\n",
    "# tqdm을 사용하여 zip을 감싸줍니다.\n",
    "for sentence, raw_context in tqdm(zip(sentence_token, data.values()), total=len(sentence_token)):\n",
    "    labels = {\"label\": []}\n",
    "    para = {\"para\": []}\n",
    "    len_token = tokenizer.tokenize(sentence)\n",
    "\n",
    "    # 입력 길이 초과 처리\n",
    "    if len(len_token) >= 512:\n",
    "        len_token = len_token[:500]\n",
    "\n",
    "    context = tokenizer.convert_tokens_to_string(len_token)\n",
    "\n",
    "    labels[\"context\"] = raw_context[\"sentence\"]\n",
    "    labels[\"label\"].extend(pip(context))\n",
    "\n",
    "    para[\"para\"].append(labels)\n",
    "    Similar_data[\"data\"].append(para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Similar_data.json', 'w', encoding='utf-8') as file :\n",
    "    json.dump(Similar_data, file, indent='\\t', ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
